sent_word_prob: word # sent
config: bleu # noise # test_classifier, train_classifier , subj_obj_data...
tasks: [test_word_prob] # [obj_number , subj_number, past_present, bigram_shift]
tasks_word: [pos]
train_test: [train, test]
server_path: /local/anasbori/
lokal_path: /home/anastasia/PycharmProjects/
data_path_in: visrepProb/word_level/ # visrepProb/task_encs/
noise_test_file_in: test_raw_sentences.npy  #test_raw_sentences.npy
noise_test_labels_in: test_raw_labels.npy # test_raw_labels.npy
test_file_out: test_raw_sentences.csv
noise_test_file_out:   test_noise_sentences.csv #test_raw_sentences.csv
noise_test_path_out: visrepProb/noise_wordlevel/
# noise_perc: [0.1, 0.2, 0.4, 0.8]
# noise_type: ['swap', 'cam', 'l33t']
pos_path_in: de-utb/
pos_file: de-train.tt #stunde.tt # de-train.tt # train_dummy.tt
xprobe_path_in: xprobe/de/
xprobe_train_file: tense_tr_out.csv
xprobe_test_file: tense_te_out.csv
# !! dataset_size: always spezify greatest value first; used to create encodings dataset !!
dataset_size: [10000, 1000] # [10000, 1000] #[20, 10]
path_scores: visrepProb/test_scores/
path_saved_classifier: 10000_sav/ # s-o-l_path + data_path_in + task + m_type + path_saved_classifier 
path_file_bleu_scores: visrepProb/noise/noise_bleu_scores.csv
path_file_bleu_scores_mttt: visrepProb/noise/MTTT_noise_bleu_scores.csv
